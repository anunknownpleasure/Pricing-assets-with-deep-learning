{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V6E1",
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anunknownpleasure/Pricing-assets-with-deep-learning/blob/main/Asset_pricing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bde5d1ca"
      },
      "source": [
        "# Explanation of the Notebook\n",
        "\n",
        "This notebook demonstrates an approach to asset pricing using a Generative Adversarial Network (GAN) framework, incorporating Fama-French factors and macroeconomic indicators. The goal is to learn a Stochastic Discount Factor (SDF) that can price a set of test assets (Fama-French 25 portfolios).\n",
        "\n",
        "## 1. Installing Libraries\n",
        "\n",
        "This section installs the necessary Python libraries for data fetching, manipulation, and model building.\n",
        "- `getFamaFrenchFactors`: To download Fama-French factor data.\n",
        "- `pandas_datareader`: To download macroeconomic data from FRED and Fama-French portfolio data.\n",
        "- `lxml`: A dependency for `pandas_datareader`.\n",
        "- `optuna`: For hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q getFamaFrenchFactors pandas_datareader lxml optuna"
      ],
      "metadata": {
        "id": "KaW8dHsaKHPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1df53fd5"
      },
      "source": [
        "## 2. Data Import and Preprocessing\n",
        "\n",
        "This section handles the loading and initial processing of the required financial and macroeconomic data.\n",
        "\n",
        "### 2a. Importing Fama-French 5 factor data\n",
        "\n",
        "We import the daily Fama-French 5 factors (Market-Risk Free, Small-Minus-Big, High-Minus-Low, Robust-Minus-Weak, Conservative-Minus-Aggressive) and the Risk-Free Rate. The factors are adjusted from percentage to decimal form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5b4c86d",
        "outputId": "6a57c6f1-1f66-4966-d5ce-3b15ecf179d4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import getFamaFrenchFactors\n",
        "\n",
        "print(\"Successfully imported getFamaFrenchFactors!\")\n",
        "print(dir(getFamaFrenchFactors))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported getFamaFrenchFactors!\n",
            "['BeautifulSoup', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '__warningregistry__', 'all_factor_links', 'all_factors_text', 'bold_tags', 'carhart4Factor', 'csv_links', 'factor_dict', 'famaFrench3Factor', 'famaFrench5Factor', 'ff3factor_dict', 'home_url', 'link', 'links_for_factor', 'momAndOthers_dict', 'momentumFactor', 'pd', 'relativedelta', 'requests', 'response', 'sib', 'soup', 'text', 'text_to_search', 'txt_links', 'url']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74d4807d"
      },
      "source": [
        "from getFamaFrenchFactors import famaFrench5Factor\n",
        "\n",
        "\n",
        "# Get the factors\n",
        "factors_df = famaFrench5Factor()\n",
        "\n",
        "# Adjust from percentage\n",
        "factors_df[['Mkt-RF', 'SMB', 'HML', 'RF']] = factors_df[['Mkt-RF', 'SMB', 'HML', 'RF']] / 100\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "1c13072c",
        "outputId": "ef88f8d2-844a-4465-e597-5cccb685b3f6"
      },
      "source": [
        "factors_df.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   date_ff_factors    Mkt-RF       SMB       HML     RMW     CMA        RF\n",
              "0       1963-07-31 -0.000039 -0.000048 -0.000081  0.0064 -0.0115  0.000027\n",
              "1       1963-08-31  0.000508 -0.000080  0.000170  0.0040 -0.0038  0.000025\n",
              "2       1963-09-30 -0.000157 -0.000043  0.000000 -0.0078  0.0015  0.000027\n",
              "3       1963-10-31  0.000254 -0.000134 -0.000004  0.0279 -0.0225  0.000029\n",
              "4       1963-11-30 -0.000086 -0.000085  0.000173 -0.0043  0.0227  0.000027\n",
              "5       1963-12-31  0.000183 -0.000189 -0.000021  0.0012 -0.0025  0.000029\n",
              "6       1964-01-31  0.000227  0.000010  0.000163  0.0021  0.0148  0.000030\n",
              "7       1964-02-29  0.000155  0.000033  0.000281  0.0011  0.0081  0.000026\n",
              "8       1964-03-31  0.000141  0.000141  0.000329 -0.0203  0.0298  0.000031\n",
              "9       1964-04-30  0.000011 -0.000148 -0.000054 -0.0132 -0.0113  0.000029\n",
              "10      1964-05-31  0.000141 -0.000062  0.000181 -0.0015  0.0013  0.000026\n",
              "11      1964-06-30  0.000127  0.000013  0.000068 -0.0033  0.0010  0.000030\n",
              "12      1964-07-31  0.000174  0.000050  0.000079  0.0015  0.0185  0.000030\n",
              "13      1964-08-31 -0.000144  0.000029  0.000007  0.0015  0.0031  0.000028\n",
              "14      1964-09-30  0.000269 -0.000034  0.000172 -0.0050  0.0056  0.000028\n",
              "15      1964-10-31  0.000060  0.000090  0.000108 -0.0020  0.0052  0.000029\n",
              "16      1964-11-30 -0.000001 -0.000024 -0.000204  0.0071 -0.0016  0.000029\n",
              "17      1964-12-31  0.000004 -0.000065 -0.000243  0.0095 -0.0155  0.000031\n",
              "18      1965-01-31  0.000354  0.000250  0.000036  0.0094 -0.0002  0.000028\n",
              "19      1965-02-28  0.000044  0.000324  0.000022  0.0026 -0.0062  0.000030"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3adb5ee-21bc-4f1e-8fee-941f410c293a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_ff_factors</th>\n",
              "      <th>Mkt-RF</th>\n",
              "      <th>SMB</th>\n",
              "      <th>HML</th>\n",
              "      <th>RMW</th>\n",
              "      <th>CMA</th>\n",
              "      <th>RF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1963-07-31</td>\n",
              "      <td>-0.000039</td>\n",
              "      <td>-0.000048</td>\n",
              "      <td>-0.000081</td>\n",
              "      <td>0.0064</td>\n",
              "      <td>-0.0115</td>\n",
              "      <td>0.000027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1963-08-31</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>-0.000080</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>0.000025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1963-09-30</td>\n",
              "      <td>-0.000157</td>\n",
              "      <td>-0.000043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.0078</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.000027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1963-10-31</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>-0.000134</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>0.0279</td>\n",
              "      <td>-0.0225</td>\n",
              "      <td>0.000029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1963-11-30</td>\n",
              "      <td>-0.000086</td>\n",
              "      <td>-0.000085</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0227</td>\n",
              "      <td>0.000027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1963-12-31</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>-0.000189</td>\n",
              "      <td>-0.000021</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>-0.0025</td>\n",
              "      <td>0.000029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1964-01-31</td>\n",
              "      <td>0.000227</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.0021</td>\n",
              "      <td>0.0148</td>\n",
              "      <td>0.000030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1964-02-29</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000281</td>\n",
              "      <td>0.0011</td>\n",
              "      <td>0.0081</td>\n",
              "      <td>0.000026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1964-03-31</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.000329</td>\n",
              "      <td>-0.0203</td>\n",
              "      <td>0.0298</td>\n",
              "      <td>0.000031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1964-04-30</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>-0.000148</td>\n",
              "      <td>-0.000054</td>\n",
              "      <td>-0.0132</td>\n",
              "      <td>-0.0113</td>\n",
              "      <td>0.000029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1964-05-31</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>-0.000062</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>0.000026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1964-06-30</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>-0.0033</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.000030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1964-07-31</td>\n",
              "      <td>0.000174</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0185</td>\n",
              "      <td>0.000030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1964-08-31</td>\n",
              "      <td>-0.000144</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.000028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1964-09-30</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>-0.000034</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>-0.0050</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.000028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1964-10-31</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>-0.0020</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.000029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1964-11-30</td>\n",
              "      <td>-0.000001</td>\n",
              "      <td>-0.000024</td>\n",
              "      <td>-0.000204</td>\n",
              "      <td>0.0071</td>\n",
              "      <td>-0.0016</td>\n",
              "      <td>0.000029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1964-12-31</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>-0.000065</td>\n",
              "      <td>-0.000243</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>-0.0155</td>\n",
              "      <td>0.000031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1965-01-31</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>0.000028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1965-02-28</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000324</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.0026</td>\n",
              "      <td>-0.0062</td>\n",
              "      <td>0.000030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3adb5ee-21bc-4f1e-8fee-941f410c293a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3adb5ee-21bc-4f1e-8fee-941f410c293a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3adb5ee-21bc-4f1e-8fee-941f410c293a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-94f507db-7d04-4137-97c3-fc13c46ee21c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94f507db-7d04-4137-97c3-fc13c46ee21c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-94f507db-7d04-4137-97c3-fc13c46ee21c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "factors_df",
              "summary": "{\n  \"name\": \"factors_df\",\n  \"rows\": 746,\n  \"fields\": [\n    {\n      \"column\": \"date_ff_factors\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1963-07-31 00:00:00\",\n        \"max\": \"2025-08-31 00:00:00\",\n        \"num_unique_values\": 746,\n        \"samples\": [\n          \"1980-11-30 00:00:00\",\n          \"1985-02-28 00:00:00\",\n          \"1971-08-31 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mkt-RF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0004469291105487263,\n        \"min\": -0.0023190000000000003,\n        \"max\": 0.00161,\n        \"num_unique_values\": 582,\n        \"samples\": [\n          -0.0001,\n          0.000118,\n          5.2e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00030326460890601174,\n        \"min\": -0.0015539999999999998,\n        \"max\": 0.0018460000000000002,\n        \"num_unique_values\": 535,\n        \"samples\": [\n          -0.000727,\n          0.000298,\n          0.00021\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HML\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0002972621685684394,\n        \"min\": -0.0013830000000000001,\n        \"max\": 0.0012859999999999998,\n        \"num_unique_values\": 525,\n        \"samples\": [\n          -4.9e-05,\n          0.000226,\n          0.00016299999999999998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMW\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.022166223929110156,\n        \"min\": -0.1895,\n        \"max\": 0.1305,\n        \"num_unique_values\": 452,\n        \"samples\": [\n          -0.0024,\n          0.0466,\n          -0.0694\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CMA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020608797890646315,\n        \"min\": -0.0708,\n        \"max\": 0.0901,\n        \"num_unique_values\": 477,\n        \"samples\": [\n          -0.0121,\n          -0.0092,\n          -0.009899999999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6217074041568368e-05,\n        \"min\": 0.0,\n        \"max\": 0.00013500000000000003,\n        \"num_unique_values\": 105,\n        \"samples\": [\n          5.7999999999999994e-05,\n          9.8e-05,\n          9.2e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We adjust the start date to -1-31-1964"
      ],
      "metadata": {
        "id": "Vq7WG9_reGfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FFdata = factors_df.iloc[6:]\n",
        "FFdata['date_ff_factors'] = pd.to_datetime(FFdata['date_ff_factors'])\n",
        "FFdata = FFdata.set_index('date_ff_factors')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFAo62NmNBJv",
        "outputId": "2b4a1953-35a1-4883-c8ec-f03065315971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4197135584.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  FFdata['date_ff_factors'] = pd.to_datetime(FFdata['date_ff_factors'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ca990d4"
      },
      "source": [
        "### 2b. Importing the macroeconomic data\n",
        "\n",
        "Macroeconomic indicators are fetched from the FRED database using `pandas_datareader`. The selected indicators include measures of the term spread, default spread, industrial production, unemployment rate, and consumer sentiment. The data is aligned to a monthly frequency and forward-filled to handle missing values."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas_datareader.data as web\n",
        "\n",
        "# --- 1. Define the 5 Long-History Macro Indicators (FRED Tickers) ---\n",
        "long_macro_tickers = {\n",
        "    'Term_Spread': 'T10YFFM',      # 10-Yr Yield minus Fed Funds Rate\n",
        "    'Default_Spread': 'AAAFFM',     # Baa Corp Yield minus Aaa Corp Yield (Risk Aversion Proxy)\n",
        "    'Ind_Production': 'INDPRO',     # Industrial Production Index\n",
        "    'Unemployment': 'UNRATE',       # Civilian Unemployment Rate\n",
        "    'Consumer_Sentiment': 'UMCSENT' # University of Michigan Consumer Sentiment\n",
        "}\n",
        "\n",
        "# --- 2. Define the Time Period\n",
        "start_date = '1964-01-01'\n",
        "end_date = '2025-08-31'\n",
        "\n",
        "# --- 3. Fetch Data from FRED ---\n",
        "try:\n",
        "    macro_data = web.DataReader(\n",
        "        list(long_macro_tickers.values()),\n",
        "        'fred',\n",
        "        start=start_date,\n",
        "        end=end_date\n",
        "    )\n",
        "    macro_data.columns = list(long_macro_tickers.keys())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error fetching data from FRED: {e}\")\n",
        "    macro_data = pd.DataFrame(index=pd.date_range(start_date, end_date, freq='M'))\n",
        "\n",
        "# --- 4. Align Data to Monthly Frequency ---\n",
        "\n",
        "# 4a. Forward-Fill any monthly gaps (common in macro data)\n",
        "macro_data = macro_data.ffill()\n",
        "\n",
        "# 4b. Ensure all data points are at the end of the month for clean alignment\n",
        "macro_data = macro_data.resample('ME').last()\n",
        "\n",
        "\n",
        "# --- 5. Display the result ---\n",
        "print(f\"Macro Data Imported and Aligned ({len(macro_data)} periods, starting {macro_data.index.min().strftime('%Y-%m')}):\")\n",
        "print(macro_data.head())\n",
        "print(\"\\n... and the tail:\")\n",
        "print(macro_data.tail())\n",
        "\n",
        "# The resulting 'macro_data' DataFrame is ready for merging with Fama-French data."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r329qKjt6fot",
        "outputId": "f5cb2b44-ae7d-4200-ff4c-e16c09192a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro Data Imported and Aligned (740 periods, starting 1964-01):\n",
            "            Term_Spread  Default_Spread  Ind_Production  Unemployment  \\\n",
            "DATE                                                                    \n",
            "1964-01-31         0.69            0.91         27.7409           5.6   \n",
            "1964-02-29         0.67            0.88         27.9291           5.4   \n",
            "1964-03-31         0.79            0.95         27.9291           5.4   \n",
            "1964-04-30         0.76            0.93         28.3861           5.3   \n",
            "1964-05-31         0.70            0.91         28.5474           5.1   \n",
            "\n",
            "            Consumer_Sentiment  \n",
            "DATE                            \n",
            "1964-01-31                 NaN  \n",
            "1964-02-29                99.5  \n",
            "1964-03-31                99.5  \n",
            "1964-04-30                99.5  \n",
            "1964-05-31                98.5  \n",
            "\n",
            "... and the tail:\n",
            "            Term_Spread  Default_Spread  Ind_Production  Unemployment  \\\n",
            "DATE                                                                    \n",
            "2025-04-30        -0.05            1.12        103.6224           4.2   \n",
            "2025-05-31         0.09            1.21        103.6570           4.2   \n",
            "2025-06-30         0.05            1.13        104.2115           4.1   \n",
            "2025-07-31         0.06            1.12        103.8194           4.2   \n",
            "2025-08-31        -0.07            1.02        103.9203           4.3   \n",
            "\n",
            "            Consumer_Sentiment  \n",
            "DATE                            \n",
            "2025-04-30                52.2  \n",
            "2025-05-31                52.2  \n",
            "2025-06-30                60.7  \n",
            "2025-07-31                61.7  \n",
            "2025-08-31                58.2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(macro_data.shape, FFdata.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGdCjtG_OEJ9",
        "outputId": "54a93db6-2801-40a4-df1d-09ff0c03c44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(740, 5) (740, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3a8bc01"
      },
      "source": [
        "### 2c. Importing the FF-portfolios\n",
        "\n",
        "The Fama-French 25 portfolios sorted by size and book-to-market are imported. These portfolios serve as the test assets that the learned SDF will attempt to price. Missing values are dropped, and returns are converted to decimal form. The index is converted to a datetime object representing the end of the month."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Define Time Period ---\n",
        "# Must match the start date used for your FF factors and macro data (e.g., 1964-01-01)\n",
        "start_date = '1964-01-01'\n",
        "end_date = '2025-08-31'\n",
        "\n",
        "# --- 2. Fetch the 25 Portfolios (Size x Book-to-Market) ---\n",
        "# The data is downloaded as a dictionary object\n",
        "ff_portfolio = web.DataReader(\n",
        "    '25_Portfolios_5x5',\n",
        "    'famafrench',\n",
        "    start=start_date,\n",
        "    end=end_date\n",
        ")\n",
        "\n",
        "df_returns_25 = ff_portfolio[0]\n",
        "\n",
        "df_returns_25 = df_returns_25.replace([-99.99, -999], np.nan) # Missing values are indicated by -99.99 or -999\n",
        "df_returns_25.dropna(inplace=True)\n",
        "\n",
        "df_returns_25 = (df_returns_25/100)# Converting from percentage to fraction\n",
        "\n",
        "# Convert PeriodIndex to DatetimeIndex at the end of the month\n",
        "df_returns_25.index = df_returns_25.index.to_timestamp(how = 'end').date\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGTrDp3eZJjV",
        "outputId": "c3c54b5f-6f41-4ae2-d987-514104837cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3312524815.py:8: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
            "  ff_portfolio = web.DataReader(\n",
            "/tmp/ipython-input-3312524815.py:8: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
            "  ff_portfolio = web.DataReader(\n",
            "/tmp/ipython-input-3312524815.py:8: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
            "  ff_portfolio = web.DataReader(\n",
            "/tmp/ipython-input-3312524815.py:8: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
            "  ff_portfolio = web.DataReader(\n",
            "/tmp/ipython-input-3312524815.py:8: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
            "  ff_portfolio = web.DataReader(\n",
            "/tmp/ipython-input-3312524815.py:8: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
            "  ff_portfolio = web.DataReader(\n",
            "/tmp/ipython-input-3312524815.py:8: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
            "  ff_portfolio = web.DataReader(\n",
            "/tmp/ipython-input-3312524815.py:8: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
            "  ff_portfolio = web.DataReader(\n",
            "/tmp/ipython-input-3312524815.py:8: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
            "  ff_portfolio = web.DataReader(\n",
            "/tmp/ipython-input-3312524815.py:8: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
            "  ff_portfolio = web.DataReader(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baf1e7a8"
      },
      "source": [
        "### 2d. Combining all the data into a DataFrame\n",
        "\n",
        "The Fama-French factors, macroeconomic data, and portfolio returns are merged into a single pandas DataFrame based on their date index. Any rows with missing values after the merge are dropped."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the index into a datetime object\n",
        "macro_data.index = pd.to_datetime(macro_data.index)\n",
        "\n",
        "\n",
        "# Combine the dataframes using merge on the index\n",
        "\n",
        "combined_data_FF_macro = pd.merge(FFdata, macro_data, left_index=True, right_index=True, how='inner') # Combining FF and Macro. Dropping first row because of a null value\n",
        "\n",
        "combined_data = pd.merge(combined_data_FF_macro, df_returns_25, left_index=True, right_index=True, how='inner')\n",
        "\n",
        "combined_data.dropna(inplace=True) # Dropping NaN entries\n",
        "\n",
        "# Display the combined data\n",
        "print(\"Combined Data:\")\n",
        "display(combined_data.head())\n",
        "print(\"\\n... and the tail:\")\n",
        "display(combined_data.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "w61GjhZaMvU5",
        "outputId": "27eb036e-546c-4cad-c2bc-b77317762828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Data:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   Mkt-RF       SMB       HML     RMW     CMA        RF  \\\n",
              "date_ff_factors                                                           \n",
              "1964-02-29       0.000155  0.000033  0.000281  0.0011  0.0081  0.000026   \n",
              "1964-03-31       0.000141  0.000141  0.000329 -0.0203  0.0298  0.000031   \n",
              "1964-04-30       0.000011 -0.000148 -0.000054 -0.0132 -0.0113  0.000029   \n",
              "1964-05-31       0.000141 -0.000062  0.000181 -0.0015  0.0013  0.000026   \n",
              "1964-06-30       0.000127  0.000013  0.000068 -0.0033  0.0010  0.000030   \n",
              "\n",
              "                 Term_Spread  Default_Spread  Ind_Production  Unemployment  \\\n",
              "date_ff_factors                                                              \n",
              "1964-02-29              0.67            0.88         27.9291           5.4   \n",
              "1964-03-31              0.79            0.95         27.9291           5.4   \n",
              "1964-04-30              0.76            0.93         28.3861           5.3   \n",
              "1964-05-31              0.70            0.91         28.5474           5.1   \n",
              "1964-06-30              0.67            0.91         28.6280           5.2   \n",
              "\n",
              "                 ...   ME4 BM1   ME4 BM2   ME4 BM3   ME4 BM4   ME4 BM5  \\\n",
              "date_ff_factors  ...                                                     \n",
              "1964-02-29       ...  0.025943  0.015619  0.028444  0.072047  0.046121   \n",
              "1964-03-31       ...  0.017750  0.029767  0.052497  0.071287  0.007247   \n",
              "1964-04-30       ... -0.027045  0.003434  0.019784 -0.026384 -0.022805   \n",
              "1964-05-31       ...  0.011914  0.022992  0.013559  0.013281  0.040990   \n",
              "1964-06-30       ...  0.010927  0.014771  0.011035  0.024965  0.031119   \n",
              "\n",
              "                 BIG LoBM   ME5 BM2   ME5 BM3   ME5 BM4  BIG HiBM  \n",
              "date_ff_factors                                                    \n",
              "1964-02-29       0.018271  0.005232  0.010194  0.039989  0.037567  \n",
              "1964-03-31       0.011575  0.007635  0.036237  0.038382  0.001491  \n",
              "1964-04-30       0.002272  0.014745  0.008082 -0.009054  0.024147  \n",
              "1964-05-31       0.020599  0.003304  0.011776  0.042859  0.033968  \n",
              "1964-06-30       0.009744  0.028644  0.004437  0.013682  0.024217  \n",
              "\n",
              "[5 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72c452f1-2689-4a55-858d-d1a84c166a57\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mkt-RF</th>\n",
              "      <th>SMB</th>\n",
              "      <th>HML</th>\n",
              "      <th>RMW</th>\n",
              "      <th>CMA</th>\n",
              "      <th>RF</th>\n",
              "      <th>Term_Spread</th>\n",
              "      <th>Default_Spread</th>\n",
              "      <th>Ind_Production</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>...</th>\n",
              "      <th>ME4 BM1</th>\n",
              "      <th>ME4 BM2</th>\n",
              "      <th>ME4 BM3</th>\n",
              "      <th>ME4 BM4</th>\n",
              "      <th>ME4 BM5</th>\n",
              "      <th>BIG LoBM</th>\n",
              "      <th>ME5 BM2</th>\n",
              "      <th>ME5 BM3</th>\n",
              "      <th>ME5 BM4</th>\n",
              "      <th>BIG HiBM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date_ff_factors</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1964-02-29</th>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000281</td>\n",
              "      <td>0.0011</td>\n",
              "      <td>0.0081</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.88</td>\n",
              "      <td>27.9291</td>\n",
              "      <td>5.4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025943</td>\n",
              "      <td>0.015619</td>\n",
              "      <td>0.028444</td>\n",
              "      <td>0.072047</td>\n",
              "      <td>0.046121</td>\n",
              "      <td>0.018271</td>\n",
              "      <td>0.005232</td>\n",
              "      <td>0.010194</td>\n",
              "      <td>0.039989</td>\n",
              "      <td>0.037567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964-03-31</th>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.000329</td>\n",
              "      <td>-0.0203</td>\n",
              "      <td>0.0298</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.95</td>\n",
              "      <td>27.9291</td>\n",
              "      <td>5.4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017750</td>\n",
              "      <td>0.029767</td>\n",
              "      <td>0.052497</td>\n",
              "      <td>0.071287</td>\n",
              "      <td>0.007247</td>\n",
              "      <td>0.011575</td>\n",
              "      <td>0.007635</td>\n",
              "      <td>0.036237</td>\n",
              "      <td>0.038382</td>\n",
              "      <td>0.001491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964-04-30</th>\n",
              "      <td>0.000011</td>\n",
              "      <td>-0.000148</td>\n",
              "      <td>-0.000054</td>\n",
              "      <td>-0.0132</td>\n",
              "      <td>-0.0113</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.93</td>\n",
              "      <td>28.3861</td>\n",
              "      <td>5.3</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.027045</td>\n",
              "      <td>0.003434</td>\n",
              "      <td>0.019784</td>\n",
              "      <td>-0.026384</td>\n",
              "      <td>-0.022805</td>\n",
              "      <td>0.002272</td>\n",
              "      <td>0.014745</td>\n",
              "      <td>0.008082</td>\n",
              "      <td>-0.009054</td>\n",
              "      <td>0.024147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964-05-31</th>\n",
              "      <td>0.000141</td>\n",
              "      <td>-0.000062</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.91</td>\n",
              "      <td>28.5474</td>\n",
              "      <td>5.1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011914</td>\n",
              "      <td>0.022992</td>\n",
              "      <td>0.013559</td>\n",
              "      <td>0.013281</td>\n",
              "      <td>0.040990</td>\n",
              "      <td>0.020599</td>\n",
              "      <td>0.003304</td>\n",
              "      <td>0.011776</td>\n",
              "      <td>0.042859</td>\n",
              "      <td>0.033968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964-06-30</th>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>-0.0033</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.91</td>\n",
              "      <td>28.6280</td>\n",
              "      <td>5.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010927</td>\n",
              "      <td>0.014771</td>\n",
              "      <td>0.011035</td>\n",
              "      <td>0.024965</td>\n",
              "      <td>0.031119</td>\n",
              "      <td>0.009744</td>\n",
              "      <td>0.028644</td>\n",
              "      <td>0.004437</td>\n",
              "      <td>0.013682</td>\n",
              "      <td>0.024217</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  36 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72c452f1-2689-4a55-858d-d1a84c166a57')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-72c452f1-2689-4a55-858d-d1a84c166a57 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-72c452f1-2689-4a55-858d-d1a84c166a57');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4dc9647b-4481-4f62-9824-61b4672d1fa3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4dc9647b-4481-4f62-9824-61b4672d1fa3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4dc9647b-4481-4f62-9824-61b4672d1fa3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "... and the tail:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   Mkt-RF       SMB       HML     RMW     CMA        RF  \\\n",
              "date_ff_factors                                                           \n",
              "2025-04-30      -0.000084 -0.000186 -0.000340 -0.0285 -0.0267  0.000035   \n",
              "2025-05-31       0.000606 -0.000072 -0.000288  0.0126  0.0251  0.000038   \n",
              "2025-06-30       0.000486 -0.000002 -0.000160 -0.0319  0.0145  0.000034   \n",
              "2025-07-31       0.000198 -0.000015 -0.000127 -0.0029 -0.0207  0.000034   \n",
              "2025-08-31       0.000185  0.000488  0.000441 -0.0069  0.0207  0.000038   \n",
              "\n",
              "                 Term_Spread  Default_Spread  Ind_Production  Unemployment  \\\n",
              "date_ff_factors                                                              \n",
              "2025-04-30             -0.05            1.12        103.6224           4.2   \n",
              "2025-05-31              0.09            1.21        103.6570           4.2   \n",
              "2025-06-30              0.05            1.13        104.2115           4.1   \n",
              "2025-07-31              0.06            1.12        103.8194           4.2   \n",
              "2025-08-31             -0.07            1.02        103.9203           4.3   \n",
              "\n",
              "                 ...   ME4 BM1   ME4 BM2   ME4 BM3   ME4 BM4   ME4 BM5  \\\n",
              "date_ff_factors  ...                                                     \n",
              "2025-04-30       ... -0.008766 -0.012699 -0.020146 -0.039276 -0.072668   \n",
              "2025-05-31       ...  0.062577  0.050222  0.035353  0.081175  0.065826   \n",
              "2025-06-30       ...  0.020351  0.043192  0.024175  0.073815  0.058024   \n",
              "2025-07-31       ...  0.034206  0.021766  0.009013 -0.001069 -0.019303   \n",
              "2025-08-31       ...  0.036524  0.016164  0.023481  0.058848  0.071342   \n",
              "\n",
              "                 BIG LoBM   ME5 BM2   ME5 BM3   ME5 BM4  BIG HiBM  \n",
              "date_ff_factors                                                    \n",
              "2025-04-30       0.014106 -0.030129 -0.073867 -0.013472 -0.027941  \n",
              "2025-05-31       0.078077  0.061296  0.018407  0.026156  0.065684  \n",
              "2025-06-30       0.055279  0.062451  0.047405  0.036424  0.070109  \n",
              "2025-07-31       0.032949  0.014068  0.012224  0.002333 -0.013744  \n",
              "2025-08-31       0.011610  0.011927  0.030567  0.054257  0.090799  \n",
              "\n",
              "[5 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7db5f04d-99b9-4b0b-9103-d4caaebc7139\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mkt-RF</th>\n",
              "      <th>SMB</th>\n",
              "      <th>HML</th>\n",
              "      <th>RMW</th>\n",
              "      <th>CMA</th>\n",
              "      <th>RF</th>\n",
              "      <th>Term_Spread</th>\n",
              "      <th>Default_Spread</th>\n",
              "      <th>Ind_Production</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>...</th>\n",
              "      <th>ME4 BM1</th>\n",
              "      <th>ME4 BM2</th>\n",
              "      <th>ME4 BM3</th>\n",
              "      <th>ME4 BM4</th>\n",
              "      <th>ME4 BM5</th>\n",
              "      <th>BIG LoBM</th>\n",
              "      <th>ME5 BM2</th>\n",
              "      <th>ME5 BM3</th>\n",
              "      <th>ME5 BM4</th>\n",
              "      <th>BIG HiBM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date_ff_factors</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-04-30</th>\n",
              "      <td>-0.000084</td>\n",
              "      <td>-0.000186</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.0285</td>\n",
              "      <td>-0.0267</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>1.12</td>\n",
              "      <td>103.6224</td>\n",
              "      <td>4.2</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008766</td>\n",
              "      <td>-0.012699</td>\n",
              "      <td>-0.020146</td>\n",
              "      <td>-0.039276</td>\n",
              "      <td>-0.072668</td>\n",
              "      <td>0.014106</td>\n",
              "      <td>-0.030129</td>\n",
              "      <td>-0.073867</td>\n",
              "      <td>-0.013472</td>\n",
              "      <td>-0.027941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-05-31</th>\n",
              "      <td>0.000606</td>\n",
              "      <td>-0.000072</td>\n",
              "      <td>-0.000288</td>\n",
              "      <td>0.0126</td>\n",
              "      <td>0.0251</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.09</td>\n",
              "      <td>1.21</td>\n",
              "      <td>103.6570</td>\n",
              "      <td>4.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.062577</td>\n",
              "      <td>0.050222</td>\n",
              "      <td>0.035353</td>\n",
              "      <td>0.081175</td>\n",
              "      <td>0.065826</td>\n",
              "      <td>0.078077</td>\n",
              "      <td>0.061296</td>\n",
              "      <td>0.018407</td>\n",
              "      <td>0.026156</td>\n",
              "      <td>0.065684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-06-30</th>\n",
              "      <td>0.000486</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>-0.000160</td>\n",
              "      <td>-0.0319</td>\n",
              "      <td>0.0145</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1.13</td>\n",
              "      <td>104.2115</td>\n",
              "      <td>4.1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020351</td>\n",
              "      <td>0.043192</td>\n",
              "      <td>0.024175</td>\n",
              "      <td>0.073815</td>\n",
              "      <td>0.058024</td>\n",
              "      <td>0.055279</td>\n",
              "      <td>0.062451</td>\n",
              "      <td>0.047405</td>\n",
              "      <td>0.036424</td>\n",
              "      <td>0.070109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-07-31</th>\n",
              "      <td>0.000198</td>\n",
              "      <td>-0.000015</td>\n",
              "      <td>-0.000127</td>\n",
              "      <td>-0.0029</td>\n",
              "      <td>-0.0207</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.12</td>\n",
              "      <td>103.8194</td>\n",
              "      <td>4.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034206</td>\n",
              "      <td>0.021766</td>\n",
              "      <td>0.009013</td>\n",
              "      <td>-0.001069</td>\n",
              "      <td>-0.019303</td>\n",
              "      <td>0.032949</td>\n",
              "      <td>0.014068</td>\n",
              "      <td>0.012224</td>\n",
              "      <td>0.002333</td>\n",
              "      <td>-0.013744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-08-31</th>\n",
              "      <td>0.000185</td>\n",
              "      <td>0.000488</td>\n",
              "      <td>0.000441</td>\n",
              "      <td>-0.0069</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>1.02</td>\n",
              "      <td>103.9203</td>\n",
              "      <td>4.3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.036524</td>\n",
              "      <td>0.016164</td>\n",
              "      <td>0.023481</td>\n",
              "      <td>0.058848</td>\n",
              "      <td>0.071342</td>\n",
              "      <td>0.011610</td>\n",
              "      <td>0.011927</td>\n",
              "      <td>0.030567</td>\n",
              "      <td>0.054257</td>\n",
              "      <td>0.090799</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  36 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7db5f04d-99b9-4b0b-9103-d4caaebc7139')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7db5f04d-99b9-4b0b-9103-d4caaebc7139 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7db5f04d-99b9-4b0b-9103-d4caaebc7139');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5fb3e627-e566-4f27-89ca-fb724d947945\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5fb3e627-e566-4f27-89ca-fb724d947945')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5fb3e627-e566-4f27-89ca-fb724d947945 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r8C41Q-U_cw",
        "outputId": "a43af605-c584-4be1-82d8-88c3834c3f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'RF', 'Term_Spread',\n",
              "       'Default_Spread', 'Ind_Production', 'Unemployment',\n",
              "       'Consumer_Sentiment', 'SMALL LoBM', 'ME1 BM2', 'ME1 BM3', 'ME1 BM4',\n",
              "       'SMALL HiBM', 'ME2 BM1', 'ME2 BM2', 'ME2 BM3', 'ME2 BM4', 'ME2 BM5',\n",
              "       'ME3 BM1', 'ME3 BM2', 'ME3 BM3', 'ME3 BM4', 'ME3 BM5', 'ME4 BM1',\n",
              "       'ME4 BM2', 'ME4 BM3', 'ME4 BM4', 'ME4 BM5', 'BIG LoBM', 'ME5 BM2',\n",
              "       'ME5 BM3', 'ME5 BM4', 'BIG HiBM'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FF_columns = combined_data.columns[:6]\n",
        "macro_columns = combined_data.columns[6:11]\n",
        "portfolio_columns = combined_data.columns[11:]\n",
        "\n",
        "no_of_FF_features = len(FF_columns)\n",
        "no_macro_features = len(macro_columns)\n",
        "no_of_portfolios = len(portfolio_columns)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i3VYDQ7uqUQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53b0358f"
      },
      "source": [
        "### 2e. Data Processing\n",
        "\n",
        "The combined data is scaled using `StandardScaler` to have zero mean and unit variance. This is a common preprocessing step for neural networks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "processed_data = scaler.fit_transform(combined_data)\n",
        "processed_data[:5]\n",
        "\n",
        "processed_data.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T8WsN3VOadF",
        "outputId": "f4c886f1-5060-4082-f803-2bfa8a2135c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(739, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ce74212"
      },
      "source": [
        "### 2f. Creating rolling windows for LSTM input\n",
        "\n",
        "A `rolling_window` function is defined to create sequential data for the LSTM layer in the Generator network. Macroeconomic data is processed into 12-month lookback windows. The Fama-French factors and portfolio returns are aligned with the end of these windows."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create rolling windows for LSTM input"
      ],
      "metadata": {
        "id": "NPLqY9ClVNh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create rolling windows on a timeseries data\n",
        "\n",
        "def rolling_window(data, lookback):\n",
        "  x_rolling = []\n",
        "  for i in range(len(data) - lookback):\n",
        "    x_rolling.append(data[i: i + lookback])\n",
        "\n",
        "  return np.array(x_rolling)\n",
        "\n",
        "lookback = 12\n",
        "ff_data = processed_data[:, :no_of_FF_features]\n",
        "macro_data = processed_data[:, no_of_FF_features: no_of_FF_features + no_macro_features]\n",
        "portfolio_data = processed_data[:, no_of_FF_features + no_macro_features:]\n",
        "\n",
        "# Creating rolling window on macro data\n",
        "X_macro_rolled = rolling_window(macro_data, lookback)\n",
        "\n",
        "# Aligning the rolling data with FF factor and Portfolio data\n",
        "X_ff_aligned = ff_data[lookback:]\n",
        "Y_targets_aligned = portfolio_data[lookback:]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "laISdiCOU2tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62099e91"
      },
      "source": [
        "### 2g. Creating Dataset and DataLoaders\n",
        "\n",
        "A custom PyTorch `Dataset` (`AssetPricingDataset`) is created to handle the macro time series, Fama-French factors, and target portfolio returns. The data is split into training, validation, and testing sets. `DataLoader` objects are created to efficiently load data in batches during training."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Dataset\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset # Import Subset\n",
        "\n",
        "class AssetPricingDataset(Dataset):\n",
        "\n",
        "    def __init__(self, macro_data, ff_data, target_data):\n",
        "        # 1. Convert all data to PyTorch tensors\n",
        "        #    We use .float() for all data as they are continuous variables.\n",
        "        self.X_macro = torch.tensor(macro_data).float()\n",
        "        self.X_ff = torch.tensor(ff_data).float()\n",
        "        self.Y_targets = torch.tensor(target_data).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_macro)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'macro_X': self.X_macro[idx],    # Shape: [12, 5]\n",
        "            'ff_X': self.X_ff[idx],          # Shape: [6]\n",
        "            'target_Y': self.Y_targets[idx]  # Shape: [25]\n",
        "        }\n",
        "\n",
        "data = AssetPricingDataset(X_macro_rolled, X_ff_aligned, Y_targets_aligned)\n",
        "no_of_samples = len(data)\n",
        "train_size = int(len(data)*0.8)\n",
        "val_size = int(len(data)*0.1)\n",
        "\n",
        "\n",
        "# Use Subset to create train and test datasets\n",
        "indices = list(range(no_of_samples))\n",
        "train_indices = indices[:train_size]\n",
        "val_indices = indices[train_size: train_size+val_size]\n",
        "test_indices = indices[train_size+val_size:]\n",
        "\n",
        "train_data = Subset(data, train_indices)\n",
        "val_data = Subset(data, val_indices)\n",
        "test_data = Subset(data, test_indices)\n",
        "\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = DataLoader(dataset = train_data, batch_size=BATCH_SIZE, shuffle = True, drop_last = True)\n",
        "val_dataset = DataLoader(dataset = val_data, batch_size=BATCH_SIZE, shuffle = True, drop_last = True)\n",
        "test_dataset = DataLoader(dataset = test_data, batch_size=BATCH_SIZE, shuffle = False, drop_last = False)"
      ],
      "metadata": {
        "id": "ZcBTXalHV-e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eeea857"
      },
      "source": [
        "# Model Architecture\n",
        "\n",
        "This section defines the architecture of the Generator and Discriminator networks within the GAN framework.\n",
        "\n",
        "## Generator (SDF Network)\n",
        "\n",
        "The Generator takes macroeconomic time series (processed by an LSTM) and Fama-French factors as input. It outputs portfolio weights that define the Stochastic Discount Factor (SDF). The SDF is constructed as $M = 1 - \\omega'R$, where $\\omega$ are the predicted weights and $R$ are the asset returns.\n",
        "\n",
        "## Discriminator (Conditioning Network)\n",
        "\n",
        "The Discriminator takes the hidden state from the Generator's LSTM and the Fama-French factors as input. It outputs conditioning instruments ($g$) used in the no-arbitrage pricing condition. The no-arbitrage condition states that the expected value of the product of the SDF and any asset return, conditional on information $g$, is zero: $E[R_i M | g] = 0$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d7a808f"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    Generator (SDF Network)\n",
        "\n",
        "    Inputs:\n",
        "    - macro_X: Macro time series [batch, seq_len, macro_dim]\n",
        "    - ff_X: Fama-French factors [batch, ff_dim]\n",
        "\n",
        "    Output:\n",
        "    - omega: SDF portfolio weights [batch, num_assets]\n",
        "    - h_t: Hidden macro states [batch, hidden_dim]\n",
        "    \"\"\"\n",
        "    def __init__(self, macro_dim, ff_dim, hidden_dim, lstm_layers, num_assets):\n",
        "        super().__init__()\n",
        "\n",
        "        # LSTM for processing macro time series\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=macro_dim,\n",
        "            hidden_size=macro_dim,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=0.05 if lstm_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Feedforward network: [hidden_states + FF_factors] -> portfolio_weights\n",
        "        self.fc1 = nn.Linear(macro_dim + ff_dim, hidden_dim)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dim // 2)\n",
        "\n",
        "        # Output layer: portfolio weights for each asset\n",
        "        self.fc3 = nn.Linear(hidden_dim//2, num_assets)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.05)\n",
        "\n",
        "    def forward(self, macro_X, ff_X):\n",
        "        # Process macro time series with LSTM\n",
        "        _, (h_n, c_n) = self.lstm(macro_X)\n",
        "        h_t = h_n[-1]  # Take last hidden state\n",
        "\n",
        "        # Combine macro states with FF factors\n",
        "        combined = torch.cat([h_t, ff_X], dim=1)\n",
        "\n",
        "        # Feedforward layers\n",
        "        x = self.fc1(combined)\n",
        "        x = self.bn1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Output: portfolio weights (omega)\n",
        "        omega = self.fc3(x)\n",
        "\n",
        "        return omega, h_t\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Discriminator (Conditioning Network)\n",
        "\n",
        "    Inputs:\n",
        "    - h_t: Hidden macro states [batch, hidden_dim]\n",
        "    - ff_X: FF factors [batch, ff_dim]\n",
        "\n",
        "    Output:\n",
        "    - g: Conditioning instruments [batch, num_instruments]\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_dim, ff_dim, num_instruments, hidden_layer):\n",
        "        super().__init__()\n",
        "\n",
        "        input_dim = hidden_dim + ff_dim\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_layer)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_layer)\n",
        "        self.fc2 = nn.Linear(hidden_layer, hidden_layer // 2)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_layer // 2)\n",
        "        self.fc3 = nn.Linear(hidden_layer // 2, num_instruments)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.05)\n",
        "\n",
        "    def forward(self, h_t, ff_X):\n",
        "        # Combine macro states with FF factors\n",
        "        x = torch.cat([h_t, ff_X], dim=1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Output: conditioning instruments\n",
        "        g = torch.tanh(self.fc3(x))  # Bounded in [-1, 1]\n",
        "\n",
        "        return g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7480a1b5"
      },
      "source": [
        "# Loss Function\n",
        "\n",
        "This section defines the loss functions used to train the Generator and Discriminator networks.\n",
        "\n",
        "- `calculate_SDF`: Computes the Stochastic Discount Factor given portfolio weights and returns.\n",
        "- `no_arbitrage_loss`: Calculates the pricing errors based on the no-arbitrage condition $E[R_i M g] = 0$. The loss is the mean squared pricing error.\n",
        "- `discriminator_loss`: The loss function for the Discriminator, which aims to maximize the no-arbitrage loss plus a regularization term.\n",
        "- `generator_loss`: The loss function for the Generator, which aims to minimize the no-arbitrage loss plus a regularization term on the weights."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "\n",
        "def calculate_SDF(weights, returns):\n",
        "\n",
        "  weighted_returns = (weights*returns).sum(dim=1, keepdim=True)\n",
        "  sdf_m = 1 - weighted_returns\n",
        "\n",
        "  return sdf_m\n",
        "\n",
        "def no_arbitrage_loss(weights, returns, g_instruments, num_assets):\n",
        "\n",
        "  sdf = calculate_SDF(weights, returns)\n",
        "  g_expanded = g_instruments.mean(dim=1, keepdim=True).expand(-1, num_assets)\n",
        "  pricing_errors = sdf*returns*g_expanded\n",
        "  mean_errors = pricing_errors.mean(dim = 0)\n",
        "  loss = (mean_errors**2).mean()\n",
        "  return loss\n",
        "\n",
        "\n",
        "def discriminator_loss(weights, returns, g_instruments, num_assets):\n",
        "\n",
        "  na_loss = no_arbitrage_loss(weights, returns, g_instruments, num_assets)\n",
        "  D_regularization_term = 0.01*(g_instruments**2).mean()\n",
        "\n",
        "  return -na_loss + D_regularization_term\n",
        "\n",
        "def generator_loss(weights, returns, g_instruments, num_assets):\n",
        "\n",
        "  na_loss = no_arbitrage_loss(weights, returns, g_instruments, num_assets)\n",
        "  G_regularization_term = 0.01*(weights**2).mean()\n",
        "\n",
        "  return na_loss + G_regularization_term\n",
        "\n"
      ],
      "metadata": {
        "id": "3bHM5INGvZ2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76bcc5d5"
      },
      "source": [
        "# Model Training\n",
        "\n",
        "This section implements the training loop for the GAN. The Discriminator is trained to maximize the no-arbitrage loss, while the Generator is trained to minimize it. The training process alternates between updating the Discriminator and the Generator."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "# training loop\n",
        "\n",
        "def training(generator, discriminator, train_loader, epochs, d_lr, g_lr):\n",
        "  D_optim = optim.Adam(discriminator.parameters(), lr = d_lr)\n",
        "  G_optim = optim.Adam(generator.parameters(), lr = g_lr)\n",
        "\n",
        "  d_losses = []\n",
        "  g_losses = []\n",
        "\n",
        "  generator.train()\n",
        "  discriminator.train()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    epoch_g_loss = 0\n",
        "    epoch_d_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "      macro_X = batch['macro_X']\n",
        "      ff_X = batch['ff_X']\n",
        "      returns = batch['target_Y']\n",
        "\n",
        "    # Training the discriminator (trained twice)\n",
        "      for i in range(2):\n",
        "        D_optim.zero_grad()\n",
        "\n",
        "        # Generate SDF weights\n",
        "        weights, h_t = generator(macro_X, ff_X)\n",
        "\n",
        "        # Generate conditioning instruments\n",
        "        g_inst = discriminator(h_t.detach(), ff_X)\n",
        "\n",
        "        # Compute discriminator loss (weights are detached to above updating generator weights)\n",
        "        d_loss = discriminator_loss(weights.detach(), returns, g_inst, no_of_portfolios)\n",
        "\n",
        "        # Backprop on discriminator\n",
        "        d_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(discriminator.parameters(), max_norm=1.0)\n",
        "        D_optim.step()\n",
        "\n",
        "\n",
        "    # Training the generator\n",
        "      G_optim.zero_grad()\n",
        "    # Generate SDF weights\n",
        "      weights, h_t = generator(macro_X, ff_X)\n",
        "\n",
        "    # Conditioning instruments\n",
        "      g_inst = discriminator(h_t.detach(), ff_X)\n",
        "    # Computer generator loss\n",
        "      g_loss = generator_loss(weights, returns, g_inst.detach(), no_of_portfolios)\n",
        "    # Backprop on generator\n",
        "      g_loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(generator.parameters(), max_norm=1.0)\n",
        "      G_optim.step()\n",
        "\n",
        "      epoch_g_loss += g_loss.item()\n",
        "      epoch_d_loss += d_loss.item()\n",
        "      num_batches += 1\n",
        "\n",
        "    # Average losses in an epoch\n",
        "\n",
        "    avg_g_loss = epoch_g_loss / num_batches\n",
        "    avg_d_loss = epoch_d_loss / num_batches\n",
        "\n",
        "    g_losses.append(avg_g_loss)\n",
        "    d_losses.append(avg_d_loss)\n",
        "\n",
        "    # Moniter the loss\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "      print(f'Epoch [{epoch+1}/{epochs}], G Loss: {avg_g_loss:.6f}, D Loss: {avg_d_loss:.6f}')\n",
        "\n",
        "  return g_losses, d_losses\n",
        "\n"
      ],
      "metadata": {
        "id": "9XZCCMqgOtvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6629559"
      },
      "source": [
        "# Baseline Models\n",
        "\n",
        "This section defines baseline models for comparison with the GAN.\n",
        "\n",
        "## 1. Fama-French linear model\n",
        "\n",
        "This baseline estimates the traditional Fama-French 5-factor model for each portfolio and calculates metrics like Sharpe Ratio and average absolute alpha.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def baseline_fama_french_5(train_loader, test_loader):\n",
        "    \"\"\"\n",
        "    Baseline 1: Fama-French 5-Factor Model\n",
        "\n",
        "    Traditional factor model:\n",
        "    R_i,t = _i + 'F_t + _i,t\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"BASELINE 1: Fama-French 5-Factor Model\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Collect all data\n",
        "    train_returns = []\n",
        "    train_ff = []\n",
        "    test_returns = []\n",
        "    test_ff = []\n",
        "\n",
        "    for batch in train_loader:\n",
        "        train_returns.append(batch['target_Y'].numpy())\n",
        "        train_ff.append(batch['ff_X'].numpy())\n",
        "\n",
        "    for batch in test_loader:\n",
        "        test_returns.append(batch['target_Y'].numpy())\n",
        "        test_ff.append(batch['ff_X'].numpy())\n",
        "\n",
        "    train_returns = np.concatenate(train_returns, axis=0)\n",
        "    train_ff = np.concatenate(train_ff, axis=0)\n",
        "    test_returns = np.concatenate(test_returns, axis=0)\n",
        "    test_ff = np.concatenate(test_ff, axis=0)\n",
        "\n",
        "    # Use first 5 FF factors (excluding RF)\n",
        "    train_ff = train_ff[:, :5]  # Mkt-RF, SMB, HML, RMW, CMA\n",
        "    test_ff = test_ff[:, :5]\n",
        "\n",
        "    # Estimate factor loadings for each portfolio\n",
        "    betas = []\n",
        "    alphas = []\n",
        "\n",
        "    for i in range(train_returns.shape[1]):\n",
        "        model = LinearRegression()\n",
        "        model.fit(train_ff, train_returns[:, i])\n",
        "        betas.append(model.coef_)\n",
        "        alphas.append(model.intercept_)\n",
        "\n",
        "    betas = np.array(betas)\n",
        "    alphas = np.array(alphas)\n",
        "\n",
        "    # Create SDF = mean-variance efficient combination of factors\n",
        "    mean_factors = train_ff.mean(axis=0)\n",
        "    cov_factors = np.cov(train_ff.T)\n",
        "\n",
        "    try:\n",
        "        weights = np.linalg.solve(cov_factors, mean_factors)\n",
        "        train_sdf_returns = (train_ff @ weights).flatten()\n",
        "        test_sdf_returns = (test_ff @ weights).flatten()\n",
        "    except:\n",
        "        # If singular, use equal weights\n",
        "        train_sdf_returns = train_ff.mean(axis=1)\n",
        "        test_sdf_returns = test_ff.mean(axis=1)\n",
        "\n",
        "    # Compute metrics\n",
        "    train_sharpe = (train_sdf_returns.mean() / train_sdf_returns.std()) * np.sqrt(12)\n",
        "    test_sharpe = (test_sdf_returns.mean() / test_sdf_returns.std()) * np.sqrt(12)\n",
        "    avg_alpha = np.abs(alphas).mean()\n",
        "\n",
        "    print(f\"Train Sharpe Ratio: {train_sharpe:.4f}\")\n",
        "    print(f\"Test Sharpe Ratio: {test_sharpe:.4f}\")\n",
        "    print(f\"Average |Alpha|: {avg_alpha:.6f}\")\n",
        "\n",
        "    return {\n",
        "        'train_sharpe': train_sharpe,\n",
        "        'test_sharpe': test_sharpe,\n",
        "        'avg_alpha': avg_alpha,\n",
        "        'train_returns': train_sdf_returns,\n",
        "        'test_returns': test_sdf_returns\n",
        "    }"
      ],
      "metadata": {
        "id": "geTLUdlfJzRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Mean-Variance portfolio\n",
        "\n",
        "This baseline constructs a simple mean-variance efficient portfolio based on the historical mean and covariance of the portfolio returns in the training data."
      ],
      "metadata": {
        "id": "Yu-m_aokLboD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_linear_mv(train_loader, test_loader):\n",
        "    \"\"\"\n",
        "    Baseline 2: Simple Linear Mean-Variance Portfolio\n",
        "\n",
        "    Maximize: ' - '\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"BASELINE 2: Linear Mean-Variance Portfolio\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Collect returns\n",
        "    train_returns = []\n",
        "    test_returns = []\n",
        "\n",
        "    for batch in train_loader:\n",
        "        train_returns.append(batch['target_Y'].numpy())\n",
        "\n",
        "    for batch in test_loader:\n",
        "        test_returns.append(batch['target_Y'].numpy())\n",
        "\n",
        "    train_returns = np.concatenate(train_returns, axis=0)\n",
        "    test_returns = np.concatenate(test_returns, axis=0)\n",
        "\n",
        "    # Estimate mean and covariance\n",
        "    mean_ret = train_returns.mean(axis=0)\n",
        "    cov_mat = np.cov(train_returns.T)\n",
        "\n",
        "    # Solve for tangency portfolio\n",
        "    try:\n",
        "        inv_cov = np.linalg.inv(cov_mat)\n",
        "        weights = inv_cov @ mean_ret\n",
        "        weights = weights / np.abs(weights).sum()\n",
        "    except:\n",
        "        weights = np.ones(train_returns.shape[1]) / train_returns.shape[1]\n",
        "\n",
        "    # Portfolio returns\n",
        "    train_portfolio_ret = (train_returns @ weights).flatten()\n",
        "    test_portfolio_ret = (test_returns @ weights).flatten()\n",
        "\n",
        "    # Compute Sharpe ratios\n",
        "    train_sharpe = (train_portfolio_ret.mean() / train_portfolio_ret.std()) * np.sqrt(12)\n",
        "    test_sharpe = (test_portfolio_ret.mean() / test_portfolio_ret.std()) * np.sqrt(12)\n",
        "\n",
        "    print(f\"Train Sharpe Ratio: {train_sharpe:.4f}\")\n",
        "    print(f\"Test Sharpe Ratio: {test_sharpe:.4f}\")\n",
        "    print(f\"Portfolio weights range: [{weights.min():.4f}, {weights.max():.4f}]\")\n",
        "\n",
        "    return {\n",
        "        'train_sharpe': train_sharpe,\n",
        "        'test_sharpe': test_sharpe,\n",
        "        'weights': weights,\n",
        "        'train_returns': train_portfolio_ret,\n",
        "        'test_returns': test_portfolio_ret\n",
        "    }\n"
      ],
      "metadata": {
        "id": "LPGDKIbDKYjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab20d9cb"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "This section defines metrics and evaluates the performance of the trained models.\n",
        "\n",
        "## 1. Evaluation metrics\n",
        "\n",
        "The `evaluate_GAN` function calculates several metrics for the GAN model on a given dataset:\n",
        "- Sharpe Ratio: Measures the risk-adjusted return of the portfolio implied by the SDF weights.\n",
        "- Cross-sectional R: Measures how well the model-implied expected returns explain the variation in average realized returns across portfolios.\n",
        "- Mean Absolute Pricing Error, Max Pricing Error, Mean Squared Pricing Error: Measure the magnitude of the deviations from the no-arbitrage condition.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_GAN(generator, test_loader):\n",
        "\n",
        "    generator.eval()\n",
        "    all_sdf = []\n",
        "    all_returns = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            macro = batch['macro_X']\n",
        "            char = batch['ff_X']\n",
        "            returns = batch['target_Y']\n",
        "\n",
        "            # Get SDF weights\n",
        "            sdf_weights, _ = generator(macro, char)\n",
        "\n",
        "            # Construct SDF\n",
        "            sdf = 1 - (sdf_weights * returns).sum(dim=1)\n",
        "\n",
        "            all_sdf.append(sdf.numpy())\n",
        "            all_returns.append(returns.numpy())\n",
        "            all_predictions.append(sdf_weights.numpy())\n",
        "\n",
        "    sdf = np.concatenate(all_sdf)\n",
        "    returns = np.concatenate(all_returns)\n",
        "    predictions = np.concatenate(all_predictions)\n",
        "\n",
        "    # Compute metrics\n",
        "    results = {}\n",
        "\n",
        "    # 1. Sharpe Ratio\n",
        "    portfolio_returns = (predictions * returns).sum(axis=1)\n",
        "    results['sharpe_ratio'] = (portfolio_returns.mean() / portfolio_returns.std()) * np.sqrt(12)\n",
        "\n",
        "    # 2. Cross-sectional R\n",
        "    mean_returns = returns.mean(axis=0)\n",
        "    pred_returns = predictions.mean(axis=0) @ mean_returns\n",
        "    results['cross_sectional_r2'] = 1 - np.sum((mean_returns - pred_returns)**2) / np.sum((mean_returns - mean_returns.mean())**2)\n",
        "\n",
        "    # 3. Pricing errors\n",
        "    pricing_errors = (sdf.reshape(-1, 1) * returns).mean(axis=0)\n",
        "    results['mean_abs_pricing_error'] = np.abs(pricing_errors).mean()\n",
        "    results['max_pricing_error'] = np.abs(pricing_errors).max()\n",
        "    results['mean_squared_pricing_error'] = (pricing_errors**2).mean()\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "u5kZIVzzfdYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Model training and Evaluation\n",
        "\n",
        "This section trains the GAN model and evaluates its performance on the training, validation, and test datasets using the defined metrics. It also evaluates the baseline models for comparison."
      ],
      "metadata": {
        "id": "HR3hN5n-T0Sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the stabilization of training loss vs no of epoch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "macro_dim = no_macro_features\n",
        "ff_dim = no_of_FF_features\n",
        "num_assets = no_of_portfolios\n",
        "\n",
        "# Hyperparameters\n",
        "hidden_dim = 16\n",
        "lstm_layers = 4\n",
        "hidden_layer = 16\n",
        "epochs = [500,1500,2000]\n",
        "d_lr = 1e-4\n",
        "g_lr = 1e-4\n",
        "\n",
        "for epoch in epochs:\n",
        "\n",
        "  generator = Generator(macro_dim, ff_dim, hidden_dim, lstm_layers, num_assets)\n",
        "\n",
        "  discriminator =  Discriminator(macro_dim, ff_dim, num_assets, hidden_layer)\n",
        "\n",
        "  g_losses, d_losses = training(generator, discriminator, train_dataset, epoch, d_lr, g_lr)\n",
        "\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.plot(range(epoch), d_losses, label='Discriminator Loss')\n",
        "  plt.plot(range(epoch), g_losses, label='Generator Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.title(f'Discriminator and Generator Loss over {epoch} Epochs')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "R466xJRAd4E3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "1f66f83e",
        "outputId": "63c849ec-5949-4a14-afd7-03c40d97660a"
      },
      "source": [
        "Gan_train = evaluate_GAN(generator, train_dataset)\n",
        "\n",
        "print(f\"Train Sharpe Ratio: {Gan_train['sharpe_ratio']:.4f}\")\n",
        "print(f\"Train Cross-sectional R: {Gan_train['cross_sectional_r2']:.4f}\")\n",
        "print(f\"Train Mean Absolute Pricing Error: {Gan_train['mean_abs_pricing_error']:.6f}\")\n",
        "print(f\"Train Max Pricing Error: {Gan_train['max_pricing_error']:.6f}\")\n",
        "print(f\"Train Mean Squared Pricing Error: {Gan_train['mean_squared_pricing_error']:.6f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'generator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3410691972.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGan_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_GAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Sharpe Ratio: {Gan_train['sharpe_ratio']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Cross-sectional R: {Gan_train['cross_sectional_r2']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Mean Absolute Pricing Error: {Gan_train['mean_abs_pricing_error']:.6f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Gan_test = evaluate_GAN(generator, test_dataset)\n",
        "\n",
        "print(f\"Test Sharpe Ratio: {Gan_test['sharpe_ratio']:.4f}\")\n",
        "print(f\"Cross-sectional R: {Gan_test['cross_sectional_r2']:.4f}\")\n",
        "print(f\"Mean Absolute Pricing Error: {Gan_test['mean_abs_pricing_error']:.6f}\")\n",
        "print(f\"Max Pricing Error: {Gan_test['max_pricing_error']:.6f}\")\n",
        "print(f\"Mean Squared Pricing Error: {Gan_test['mean_squared_pricing_error']:.6f}\")\n",
        "#"
      ],
      "metadata": {
        "id": "sGVJP67JLeUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Fama-French Baseline\n",
        "ff_results = baseline_fama_french_5(train_dataset, test_dataset)\n",
        "\n",
        "print(\"\\nFama-French 5-Factor Model Results:\")\n",
        "print(f\"  Train Sharpe Ratio: {ff_results['train_sharpe']:.4f}\")\n",
        "print(f\"  Test Sharpe Ratio: {ff_results['test_sharpe']:.4f}\")\n",
        "print(f\"  Average |Alpha|: {ff_results['avg_alpha']:.6f}\")\n",
        "\n",
        "\n",
        "# Evaluate Mean-Variance Baseline\n",
        "mv_results = baseline_linear_mv(train_dataset, test_dataset)\n",
        "\n",
        "print(\"\\nLinear Mean-Variance Portfolio Results:\")\n",
        "print(f\"  Train Sharpe Ratio: {mv_results['train_sharpe']:.4f}\")\n",
        "print(f\"  Test Sharpe Ratio: {mv_results['test_sharpe']:.4f}\")\n",
        "print(f\"  Portfolio weights range: [{mv_results['weights'].min():.4f}, {mv_results['weights'].max():.4f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Czb_qLywON_n",
        "outputId": "218fb355-75c4-4092-ab81-6b438be3c852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "BASELINE 1: Fama-French 5-Factor Model\n",
            "============================================================\n",
            "Train Sharpe Ratio: 0.2137\n",
            "Test Sharpe Ratio: -0.4991\n",
            "Average |Alpha|: 0.011956\n",
            "\n",
            "Fama-French 5-Factor Model Results:\n",
            "  Train Sharpe Ratio: 0.2137\n",
            "  Test Sharpe Ratio: -0.4991\n",
            "  Average |Alpha|: 0.011956\n",
            "\n",
            "============================================================\n",
            "BASELINE 2: Linear Mean-Variance Portfolio\n",
            "============================================================\n",
            "Train Sharpe Ratio: 0.4009\n",
            "Test Sharpe Ratio: -0.9752\n",
            "Portfolio weights range: [-0.1320, 0.1561]\n",
            "\n",
            "Linear Mean-Variance Portfolio Results:\n",
            "  Train Sharpe Ratio: 0.4009\n",
            "  Test Sharpe Ratio: -0.9752\n",
            "  Portfolio weights range: [-0.1320, 0.1561]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b90c34ef"
      },
      "source": [
        "# Hyperparameter Tuning\n",
        "\n",
        "This section uses the Optuna library to tune the hyperparameters of the Generator and Discriminator networks to maximize the Sharpe Ratio on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "  # Define these variables within the objective function for scope\n",
        "  macro_dim = no_macro_features\n",
        "  ff_dim = no_of_FF_features\n",
        "  num_assets = no_of_portfolios\n",
        "\n",
        "\n",
        "  hidden_dim = trial.suggest_categorical('hidden_dim', [32, 64, 128])\n",
        "  lstm_layers = trial.suggest_categorical('lstm_layers', [2, 3, 4])\n",
        "  hidden_layer = trial.suggest_categorical('hidden_layer', [32, 64, 128])\n",
        "  epochs = trial.suggest_categorical('epochs', [1500, 2000])\n",
        "  d_lr = trial.suggest_loguniform('d_lr', 1e-5, 1e-3)\n",
        "  g_lr = trial.suggest_loguniform('g_lr', 1e-5, 1e-3)\n",
        "\n",
        "  generator = Generator(macro_dim, ff_dim, hidden_dim, lstm_layers, num_assets)\n",
        "  discriminator = Discriminator(macro_dim, ff_dim, num_assets, hidden_layer)\n",
        "\n",
        "  g_losses, d_losses = training(generator, discriminator, train_dataset, epochs, d_lr, g_lr)\n",
        "\n",
        "  Gan_val = evaluate_GAN(generator, val_dataset)\n",
        "\n",
        "  return Gan_val['sharpe_ratio']\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "best_params = study.best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3LVnZPYJLjf",
        "outputId": "233301a0-f08b-4fe0-88c3-cf343a52045d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-07 07:34:29,814] A new study created in memory with name: no-name-279f9994-1dce-4e11-b38d-e37dfa32b041\n",
            "/tmp/ipython-input-1988464876.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  d_lr = trial.suggest_loguniform('d_lr', 1e-5, 1e-3)\n",
            "/tmp/ipython-input-1988464876.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  g_lr = trial.suggest_loguniform('g_lr', 1e-5, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/2000], G Loss: 0.246461, D Loss: -0.236593\n",
            "Epoch [100/2000], G Loss: 0.098232, D Loss: -0.056987\n",
            "Epoch [150/2000], G Loss: 0.039525, D Loss: -0.068229\n",
            "Epoch [200/2000], G Loss: 0.030691, D Loss: -0.046510\n",
            "Epoch [250/2000], G Loss: 0.021834, D Loss: -0.019553\n",
            "Epoch [300/2000], G Loss: 0.028254, D Loss: -0.015413\n",
            "Epoch [350/2000], G Loss: 0.021077, D Loss: -0.011472\n",
            "Epoch [400/2000], G Loss: 0.038519, D Loss: -0.015835\n",
            "Epoch [450/2000], G Loss: 0.020822, D Loss: -0.009085\n",
            "Epoch [500/2000], G Loss: 0.017442, D Loss: -0.014497\n",
            "Epoch [550/2000], G Loss: 0.007362, D Loss: -0.008964\n",
            "Epoch [600/2000], G Loss: 0.007189, D Loss: -0.008726\n",
            "Epoch [650/2000], G Loss: 0.017352, D Loss: -0.002996\n",
            "Epoch [700/2000], G Loss: 0.013793, D Loss: -0.003462\n",
            "Epoch [750/2000], G Loss: 0.006153, D Loss: -0.002070\n",
            "Epoch [800/2000], G Loss: 0.006394, D Loss: -0.003498\n",
            "Epoch [850/2000], G Loss: 0.005284, D Loss: -0.004008\n",
            "Epoch [900/2000], G Loss: 0.005891, D Loss: -0.006060\n",
            "Epoch [950/2000], G Loss: 0.006340, D Loss: -0.001893\n",
            "Epoch [1000/2000], G Loss: 0.005682, D Loss: -0.005572\n",
            "Epoch [1050/2000], G Loss: 0.012595, D Loss: -0.002884\n",
            "Epoch [1100/2000], G Loss: 0.005483, D Loss: -0.004624\n",
            "Epoch [1150/2000], G Loss: 0.003950, D Loss: -0.001630\n",
            "Epoch [1200/2000], G Loss: 0.003873, D Loss: -0.001618\n",
            "Epoch [1250/2000], G Loss: 0.003047, D Loss: -0.002277\n",
            "Epoch [1300/2000], G Loss: 0.003865, D Loss: -0.000144\n",
            "Epoch [1350/2000], G Loss: 0.002962, D Loss: -0.000703\n",
            "Epoch [1400/2000], G Loss: 0.004584, D Loss: -0.000820\n",
            "Epoch [1450/2000], G Loss: 0.003080, D Loss: 0.000279\n",
            "Epoch [1500/2000], G Loss: 0.003184, D Loss: -0.000527\n",
            "Epoch [1550/2000], G Loss: 0.005004, D Loss: -0.002127\n",
            "Epoch [1600/2000], G Loss: 0.004513, D Loss: -0.000656\n",
            "Epoch [1650/2000], G Loss: 0.002906, D Loss: -0.000314\n",
            "Epoch [1700/2000], G Loss: 0.003033, D Loss: -0.000606\n",
            "Epoch [1750/2000], G Loss: 0.002602, D Loss: -0.000187\n",
            "Epoch [1800/2000], G Loss: 0.003654, D Loss: -0.000446\n",
            "Epoch [1850/2000], G Loss: 0.003048, D Loss: 0.000085\n",
            "Epoch [1900/2000], G Loss: 0.001996, D Loss: 0.001549\n",
            "Epoch [1950/2000], G Loss: 0.003328, D Loss: 0.000106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-07 07:37:16,060] Trial 0 finished with value: 3.947732042339764 and parameters: {'hidden_dim': 32, 'lstm_layers': 3, 'hidden_layer': 32, 'epochs': 2000, 'd_lr': 0.0007949367959213507, 'g_lr': 9.430549910236732e-05}. Best is trial 0 with value: 3.947732042339764.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2000/2000], G Loss: 0.004018, D Loss: 0.000949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1988464876.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  d_lr = trial.suggest_loguniform('d_lr', 1e-5, 1e-3)\n",
            "/tmp/ipython-input-1988464876.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  g_lr = trial.suggest_loguniform('g_lr', 1e-5, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/1500], G Loss: 0.031850, D Loss: -0.031111\n",
            "Epoch [100/1500], G Loss: 0.083048, D Loss: -0.011794\n",
            "Epoch [150/1500], G Loss: 0.049727, D Loss: -0.045627\n",
            "Epoch [200/1500], G Loss: 0.061754, D Loss: -0.065091\n",
            "Epoch [250/1500], G Loss: 0.058421, D Loss: -0.099139\n",
            "Epoch [300/1500], G Loss: 0.045320, D Loss: -0.098236\n",
            "Epoch [350/1500], G Loss: 0.099684, D Loss: -0.031002\n",
            "Epoch [400/1500], G Loss: 0.127302, D Loss: -0.142089\n",
            "Epoch [450/1500], G Loss: 0.053239, D Loss: -0.063330\n",
            "Epoch [500/1500], G Loss: 0.107464, D Loss: -0.030248\n",
            "Epoch [550/1500], G Loss: 0.099107, D Loss: -0.081872\n",
            "Epoch [600/1500], G Loss: 0.061889, D Loss: -0.022950\n",
            "Epoch [650/1500], G Loss: 0.138558, D Loss: -0.012140\n",
            "Epoch [700/1500], G Loss: 0.033907, D Loss: -0.033618\n",
            "Epoch [750/1500], G Loss: 0.066413, D Loss: -0.052490\n",
            "Epoch [800/1500], G Loss: 0.027744, D Loss: -0.094575\n",
            "Epoch [850/1500], G Loss: 0.011935, D Loss: -0.026548\n",
            "Epoch [900/1500], G Loss: 0.031637, D Loss: -0.007438\n",
            "Epoch [950/1500], G Loss: 0.093052, D Loss: -0.047159\n",
            "Epoch [1000/1500], G Loss: 0.019068, D Loss: -0.025517\n",
            "Epoch [1050/1500], G Loss: 0.048718, D Loss: -0.018897\n",
            "Epoch [1100/1500], G Loss: 0.073173, D Loss: -0.040909\n",
            "Epoch [1150/1500], G Loss: 0.026116, D Loss: -0.060381\n",
            "Epoch [1200/1500], G Loss: 0.016716, D Loss: -0.028316\n",
            "Epoch [1250/1500], G Loss: 0.011960, D Loss: -0.065693\n",
            "Epoch [1300/1500], G Loss: 0.032693, D Loss: -0.027042\n",
            "Epoch [1350/1500], G Loss: 0.023246, D Loss: -0.004038\n",
            "Epoch [1400/1500], G Loss: 0.051265, D Loss: -0.031252\n",
            "Epoch [1450/1500], G Loss: 0.036732, D Loss: -0.097239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-07 07:39:11,385] Trial 1 finished with value: 2.518514810268689 and parameters: {'hidden_dim': 128, 'lstm_layers': 2, 'hidden_layer': 32, 'epochs': 1500, 'd_lr': 5.497140398898081e-05, 'g_lr': 1.6115120726795183e-05}. Best is trial 0 with value: 3.947732042339764.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1500/1500], G Loss: 0.033620, D Loss: -0.097617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1988464876.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  d_lr = trial.suggest_loguniform('d_lr', 1e-5, 1e-3)\n",
            "/tmp/ipython-input-1988464876.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  g_lr = trial.suggest_loguniform('g_lr', 1e-5, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/1500], G Loss: 0.015416, D Loss: -0.002978\n",
            "Epoch [100/1500], G Loss: 0.007299, D Loss: -0.012328\n",
            "Epoch [150/1500], G Loss: 0.018373, D Loss: -0.011130\n",
            "Epoch [200/1500], G Loss: 0.005396, D Loss: -0.008504\n",
            "Epoch [250/1500], G Loss: 0.005485, D Loss: -0.001047\n",
            "Epoch [300/1500], G Loss: 0.006885, D Loss: -0.001990\n",
            "Epoch [350/1500], G Loss: 0.003382, D Loss: 0.000548\n",
            "Epoch [400/1500], G Loss: 0.001889, D Loss: 0.000318\n",
            "Epoch [450/1500], G Loss: 0.001791, D Loss: 0.000264\n",
            "Epoch [500/1500], G Loss: 0.001702, D Loss: -0.000723\n",
            "Epoch [550/1500], G Loss: 0.001367, D Loss: 0.000820\n",
            "Epoch [600/1500], G Loss: 0.001640, D Loss: 0.000526\n",
            "Epoch [650/1500], G Loss: 0.000933, D Loss: 0.000254\n",
            "Epoch [700/1500], G Loss: 0.000703, D Loss: 0.000265\n",
            "Epoch [750/1500], G Loss: 0.000603, D Loss: 0.000143\n",
            "Epoch [800/1500], G Loss: 0.000659, D Loss: 0.000091\n",
            "Epoch [850/1500], G Loss: 0.000425, D Loss: 0.000178\n",
            "Epoch [900/1500], G Loss: 0.000391, D Loss: 0.000063\n",
            "Epoch [950/1500], G Loss: 0.000358, D Loss: 0.000058\n",
            "Epoch [1000/1500], G Loss: 0.000225, D Loss: 0.000097\n",
            "Epoch [1050/1500], G Loss: 0.000233, D Loss: 0.000075\n",
            "Epoch [1100/1500], G Loss: 0.000172, D Loss: 0.000055\n",
            "Epoch [1150/1500], G Loss: 0.000156, D Loss: 0.000044\n",
            "Epoch [1200/1500], G Loss: 0.000135, D Loss: 0.000023\n",
            "Epoch [1250/1500], G Loss: 0.000137, D Loss: 0.000013\n",
            "Epoch [1300/1500], G Loss: 0.000126, D Loss: 0.000015\n",
            "Epoch [1350/1500], G Loss: 0.000137, D Loss: 0.000028\n",
            "Epoch [1400/1500], G Loss: 0.000129, D Loss: 0.000041\n",
            "Epoch [1450/1500], G Loss: 0.000113, D Loss: 0.000027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-07 07:41:09,451] Trial 2 finished with value: 4.687251743963873 and parameters: {'hidden_dim': 128, 'lstm_layers': 2, 'hidden_layer': 32, 'epochs': 1500, 'd_lr': 6.546437332816166e-05, 'g_lr': 0.00013237191687062074}. Best is trial 2 with value: 4.687251743963873.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1500/1500], G Loss: 0.000132, D Loss: 0.000011\n",
            "Epoch [50/2000], G Loss: 0.153190, D Loss: -0.028060\n",
            "Epoch [100/2000], G Loss: 0.110416, D Loss: -0.050778\n",
            "Epoch [150/2000], G Loss: 0.009349, D Loss: -0.011633\n",
            "Epoch [200/2000], G Loss: 0.012830, D Loss: -0.009716\n",
            "Epoch [250/2000], G Loss: 0.017409, D Loss: -0.002516\n",
            "Epoch [300/2000], G Loss: 0.017378, D Loss: -0.006960\n",
            "Epoch [350/2000], G Loss: 0.014822, D Loss: -0.013337\n",
            "Epoch [400/2000], G Loss: 0.005235, D Loss: -0.002084\n",
            "Epoch [450/2000], G Loss: 0.004174, D Loss: 0.000925\n",
            "Epoch [500/2000], G Loss: 0.005510, D Loss: -0.004460\n",
            "Epoch [550/2000], G Loss: 0.002324, D Loss: -0.001547\n",
            "Epoch [600/2000], G Loss: 0.002654, D Loss: 0.000778\n",
            "Epoch [650/2000], G Loss: 0.003789, D Loss: -0.001291\n",
            "Epoch [700/2000], G Loss: 0.001149, D Loss: -0.000797\n",
            "Epoch [750/2000], G Loss: 0.000597, D Loss: -0.000162\n",
            "Epoch [800/2000], G Loss: 0.001328, D Loss: -0.000039\n",
            "Epoch [850/2000], G Loss: 0.002937, D Loss: -0.000833\n",
            "Epoch [900/2000], G Loss: 0.001172, D Loss: 0.000361\n",
            "Epoch [950/2000], G Loss: 0.001874, D Loss: -0.001128\n",
            "Epoch [1000/2000], G Loss: 0.001313, D Loss: 0.000033\n",
            "Epoch [1050/2000], G Loss: 0.000519, D Loss: 0.000234\n",
            "Epoch [1100/2000], G Loss: 0.000478, D Loss: 0.000149\n",
            "Epoch [1150/2000], G Loss: 0.001127, D Loss: -0.000002\n",
            "Epoch [1200/2000], G Loss: 0.000783, D Loss: -0.000080\n",
            "Epoch [1250/2000], G Loss: 0.000574, D Loss: -0.000028\n",
            "Epoch [1300/2000], G Loss: 0.003822, D Loss: -0.001261\n",
            "Epoch [1350/2000], G Loss: 0.000220, D Loss: 0.000080\n",
            "Epoch [1400/2000], G Loss: 0.000483, D Loss: 0.000233\n",
            "Epoch [1450/2000], G Loss: 0.000548, D Loss: -0.000220\n",
            "Epoch [1500/2000], G Loss: 0.000904, D Loss: -0.000189\n",
            "Epoch [1550/2000], G Loss: 0.000829, D Loss: -0.000288\n",
            "Epoch [1600/2000], G Loss: 0.000328, D Loss: 0.000089\n",
            "Epoch [1650/2000], G Loss: 0.000198, D Loss: 0.000051\n",
            "Epoch [1700/2000], G Loss: 0.000359, D Loss: 0.000173\n",
            "Epoch [1750/2000], G Loss: 0.000787, D Loss: -0.000429\n",
            "Epoch [1800/2000], G Loss: 0.000188, D Loss: 0.000032\n",
            "Epoch [1850/2000], G Loss: 0.000157, D Loss: 0.000024\n",
            "Epoch [1900/2000], G Loss: 0.000428, D Loss: -0.000056\n",
            "Epoch [1950/2000], G Loss: 0.000716, D Loss: 0.000320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-07 07:44:49,803] Trial 3 finished with value: 6.337192197484838 and parameters: {'hidden_dim': 128, 'lstm_layers': 4, 'hidden_layer': 128, 'epochs': 2000, 'd_lr': 0.0009255789089317319, 'g_lr': 0.00012586546042489945}. Best is trial 3 with value: 6.337192197484838.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2000/2000], G Loss: 0.000222, D Loss: 0.000076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1988464876.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  d_lr = trial.suggest_loguniform('d_lr', 1e-5, 1e-3)\n",
            "/tmp/ipython-input-1988464876.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  g_lr = trial.suggest_loguniform('g_lr', 1e-5, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/1500], G Loss: 0.008441, D Loss: -0.006920\n",
            "Epoch [100/1500], G Loss: 0.011815, D Loss: -0.006283\n",
            "Epoch [150/1500], G Loss: 0.060874, D Loss: -0.014495\n",
            "Epoch [200/1500], G Loss: 0.012086, D Loss: -0.015112\n",
            "Epoch [250/1500], G Loss: 0.017199, D Loss: -0.015027\n",
            "Epoch [300/1500], G Loss: 0.005866, D Loss: -0.001725\n",
            "Epoch [350/1500], G Loss: 0.011573, D Loss: -0.015434\n",
            "Epoch [400/1500], G Loss: 0.021807, D Loss: -0.008225\n",
            "Epoch [450/1500], G Loss: 0.017290, D Loss: -0.000729\n",
            "Epoch [500/1500], G Loss: 0.013299, D Loss: -0.010950\n",
            "Epoch [550/1500], G Loss: 0.016804, D Loss: -0.003027\n",
            "Epoch [600/1500], G Loss: 0.004326, D Loss: -0.003492\n",
            "Epoch [650/1500], G Loss: 0.006101, D Loss: -0.002289\n",
            "Epoch [700/1500], G Loss: 0.008365, D Loss: -0.003641\n",
            "Epoch [750/1500], G Loss: 0.006175, D Loss: -0.005491\n",
            "Epoch [800/1500], G Loss: 0.003768, D Loss: -0.003835\n",
            "Epoch [850/1500], G Loss: 0.004558, D Loss: -0.000876\n",
            "Epoch [900/1500], G Loss: 0.009038, D Loss: -0.001275\n",
            "Epoch [950/1500], G Loss: 0.005103, D Loss: -0.001807\n",
            "Epoch [1000/1500], G Loss: 0.007560, D Loss: 0.000295\n",
            "Epoch [1050/1500], G Loss: 0.002879, D Loss: -0.002001\n",
            "Epoch [1100/1500], G Loss: 0.004962, D Loss: 0.000520\n",
            "Epoch [1150/1500], G Loss: 0.003702, D Loss: -0.001360\n",
            "Epoch [1200/1500], G Loss: 0.002024, D Loss: -0.001389\n",
            "Epoch [1250/1500], G Loss: 0.001701, D Loss: -0.001160\n",
            "Epoch [1300/1500], G Loss: 0.003556, D Loss: 0.000988\n",
            "Epoch [1350/1500], G Loss: 0.002667, D Loss: -0.000149\n",
            "Epoch [1400/1500], G Loss: 0.002249, D Loss: -0.000210\n",
            "Epoch [1450/1500], G Loss: 0.001750, D Loss: -0.000743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-07 07:46:43,438] Trial 4 finished with value: 3.2787893278439086 and parameters: {'hidden_dim': 64, 'lstm_layers': 2, 'hidden_layer': 32, 'epochs': 1500, 'd_lr': 5.1059343031010776e-05, 'g_lr': 6.849217875032407e-05}. Best is trial 3 with value: 6.337192197484838.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1500/1500], G Loss: 0.001450, D Loss: 0.000502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1988464876.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  d_lr = trial.suggest_loguniform('d_lr', 1e-5, 1e-3)\n",
            "/tmp/ipython-input-1988464876.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  g_lr = trial.suggest_loguniform('g_lr', 1e-5, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/1500], G Loss: 0.001900, D Loss: 0.000730\n",
            "Epoch [100/1500], G Loss: 0.001570, D Loss: 0.000956\n",
            "Epoch [150/1500], G Loss: 0.000737, D Loss: 0.001001\n",
            "Epoch [200/1500], G Loss: 0.000505, D Loss: 0.000867\n",
            "Epoch [250/1500], G Loss: 0.000571, D Loss: 0.000739\n",
            "Epoch [300/1500], G Loss: 0.000341, D Loss: 0.000721\n",
            "Epoch [350/1500], G Loss: 0.000338, D Loss: 0.000515\n",
            "Epoch [400/1500], G Loss: 0.000287, D Loss: 0.000418\n",
            "Epoch [450/1500], G Loss: 0.000394, D Loss: 0.000328\n",
            "Epoch [500/1500], G Loss: 0.000246, D Loss: 0.000153\n",
            "Epoch [550/1500], G Loss: 0.000356, D Loss: 0.000254\n",
            "Epoch [600/1500], G Loss: 0.000423, D Loss: 0.000296\n",
            "Epoch [650/1500], G Loss: 0.000438, D Loss: 0.000023\n",
            "Epoch [700/1500], G Loss: 0.000227, D Loss: 0.000270\n",
            "Epoch [750/1500], G Loss: 0.000377, D Loss: 0.000256\n",
            "Epoch [800/1500], G Loss: 0.000348, D Loss: 0.000134\n",
            "Epoch [850/1500], G Loss: 0.000232, D Loss: 0.000209\n",
            "Epoch [900/1500], G Loss: 0.000539, D Loss: 0.000241\n",
            "Epoch [950/1500], G Loss: 0.000223, D Loss: 0.000224\n",
            "Epoch [1000/1500], G Loss: 0.000153, D Loss: 0.000198\n",
            "Epoch [1050/1500], G Loss: 0.000192, D Loss: 0.000132\n",
            "Epoch [1100/1500], G Loss: 0.000127, D Loss: 0.000125\n",
            "Epoch [1150/1500], G Loss: 0.000261, D Loss: 0.000014\n",
            "Epoch [1200/1500], G Loss: 0.000092, D Loss: 0.000132\n",
            "Epoch [1250/1500], G Loss: 0.000091, D Loss: 0.000111\n",
            "Epoch [1300/1500], G Loss: 0.000080, D Loss: 0.000123\n",
            "Epoch [1350/1500], G Loss: 0.000275, D Loss: 0.000001\n",
            "Epoch [1400/1500], G Loss: 0.000095, D Loss: 0.000072\n",
            "Epoch [1450/1500], G Loss: 0.000078, D Loss: 0.000097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-07 07:49:12,156] Trial 5 finished with value: 3.988585491778047 and parameters: {'hidden_dim': 32, 'lstm_layers': 4, 'hidden_layer': 32, 'epochs': 1500, 'd_lr': 1.8702068869591523e-05, 'g_lr': 0.00041761390979180304}. Best is trial 3 with value: 6.337192197484838.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1500/1500], G Loss: 0.000072, D Loss: 0.000054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1988464876.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  d_lr = trial.suggest_loguniform('d_lr', 1e-5, 1e-3)\n",
            "/tmp/ipython-input-1988464876.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  g_lr = trial.suggest_loguniform('g_lr', 1e-5, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/2000], G Loss: 0.001775, D Loss: -0.000561\n",
            "Epoch [100/2000], G Loss: 0.001484, D Loss: 0.000308\n",
            "Epoch [150/2000], G Loss: 0.001665, D Loss: -0.000260\n",
            "Epoch [200/2000], G Loss: 0.001139, D Loss: 0.000572\n",
            "Epoch [250/2000], G Loss: 0.001138, D Loss: 0.000592\n",
            "Epoch [300/2000], G Loss: 0.000944, D Loss: -0.000017\n",
            "Epoch [350/2000], G Loss: 0.000837, D Loss: 0.000113\n",
            "Epoch [400/2000], G Loss: 0.000796, D Loss: 0.000299\n",
            "Epoch [450/2000], G Loss: 0.000797, D Loss: 0.000333\n",
            "Epoch [500/2000], G Loss: 0.001559, D Loss: -0.000308\n",
            "Epoch [550/2000], G Loss: 0.001284, D Loss: -0.000319\n",
            "Epoch [600/2000], G Loss: 0.000792, D Loss: 0.000237\n",
            "Epoch [650/2000], G Loss: 0.000871, D Loss: 0.000361\n",
            "Epoch [700/2000], G Loss: 0.000503, D Loss: 0.000399\n",
            "Epoch [750/2000], G Loss: 0.000495, D Loss: 0.000166\n",
            "Epoch [800/2000], G Loss: 0.000535, D Loss: 0.000132\n",
            "Epoch [850/2000], G Loss: 0.000269, D Loss: 0.000384\n",
            "Epoch [900/2000], G Loss: 0.000235, D Loss: 0.000303\n",
            "Epoch [950/2000], G Loss: 0.000583, D Loss: 0.000136\n",
            "Epoch [1000/2000], G Loss: 0.000175, D Loss: 0.000212\n",
            "Epoch [1050/2000], G Loss: 0.000163, D Loss: 0.000159\n",
            "Epoch [1100/2000], G Loss: 0.000157, D Loss: 0.000158\n",
            "Epoch [1150/2000], G Loss: 0.000168, D Loss: 0.000106\n",
            "Epoch [1200/2000], G Loss: 0.000195, D Loss: 0.000035\n",
            "Epoch [1250/2000], G Loss: 0.000084, D Loss: 0.000101\n",
            "Epoch [1300/2000], G Loss: 0.000106, D Loss: 0.000084\n",
            "Epoch [1350/2000], G Loss: 0.000103, D Loss: 0.000092\n",
            "Epoch [1400/2000], G Loss: 0.000062, D Loss: 0.000041\n",
            "Epoch [1450/2000], G Loss: 0.000124, D Loss: 0.000018\n",
            "Epoch [1500/2000], G Loss: 0.000064, D Loss: 0.000070\n",
            "Epoch [1550/2000], G Loss: 0.000066, D Loss: 0.000038\n",
            "Epoch [1600/2000], G Loss: 0.000047, D Loss: 0.000055\n",
            "Epoch [1650/2000], G Loss: 0.000058, D Loss: 0.000048\n",
            "Epoch [1700/2000], G Loss: 0.000033, D Loss: 0.000041\n",
            "Epoch [1750/2000], G Loss: 0.000040, D Loss: 0.000040\n",
            "Epoch [1800/2000], G Loss: 0.000040, D Loss: 0.000031\n",
            "Epoch [1850/2000], G Loss: 0.000028, D Loss: 0.000025\n",
            "Epoch [1900/2000], G Loss: 0.000022, D Loss: 0.000022\n",
            "Epoch [1950/2000], G Loss: 0.000106, D Loss: -0.000017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-07 07:51:41,051] Trial 6 finished with value: 3.1876489285229055 and parameters: {'hidden_dim': 32, 'lstm_layers': 2, 'hidden_layer': 64, 'epochs': 2000, 'd_lr': 2.1332381443441837e-05, 'g_lr': 0.0006565789746685719}. Best is trial 3 with value: 6.337192197484838.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2000/2000], G Loss: 0.000091, D Loss: 0.000006\n",
            "Epoch [50/2000], G Loss: 0.004165, D Loss: -0.003565\n",
            "Epoch [100/2000], G Loss: 0.002880, D Loss: 0.000276\n",
            "Epoch [150/2000], G Loss: 0.002034, D Loss: -0.001283\n",
            "Epoch [200/2000], G Loss: 0.001235, D Loss: 0.000563\n",
            "Epoch [250/2000], G Loss: 0.001376, D Loss: 0.000594\n",
            "Epoch [300/2000], G Loss: 0.000495, D Loss: 0.000840\n",
            "Epoch [350/2000], G Loss: 0.000360, D Loss: 0.000618\n",
            "Epoch [400/2000], G Loss: 0.000900, D Loss: 0.000275\n",
            "Epoch [450/2000], G Loss: 0.000364, D Loss: 0.000242\n",
            "Epoch [500/2000], G Loss: 0.000248, D Loss: 0.000228\n",
            "Epoch [550/2000], G Loss: 0.000272, D Loss: 0.000093\n",
            "Epoch [600/2000], G Loss: 0.000628, D Loss: 0.000042\n",
            "Epoch [650/2000], G Loss: 0.002592, D Loss: -0.001525\n",
            "Epoch [700/2000], G Loss: 0.000529, D Loss: 0.000780\n",
            "Epoch [750/2000], G Loss: 0.000709, D Loss: 0.000148\n",
            "Epoch [800/2000], G Loss: 0.000866, D Loss: -0.000106\n",
            "Epoch [850/2000], G Loss: 0.000383, D Loss: -0.000162\n",
            "Epoch [900/2000], G Loss: 0.000106, D Loss: 0.000069\n",
            "Epoch [950/2000], G Loss: 0.000081, D Loss: 0.000086\n",
            "Epoch [1000/2000], G Loss: 0.000087, D Loss: 0.000007\n",
            "Epoch [1050/2000], G Loss: 0.000065, D Loss: 0.000033\n",
            "Epoch [1100/2000], G Loss: 0.000057, D Loss: 0.000026\n",
            "Epoch [1150/2000], G Loss: 0.000052, D Loss: 0.000005\n",
            "Epoch [1200/2000], G Loss: 0.000053, D Loss: 0.000009\n",
            "Epoch [1250/2000], G Loss: 0.000046, D Loss: 0.000006\n",
            "Epoch [1300/2000], G Loss: 0.000036, D Loss: 0.000012\n",
            "Epoch [1350/2000], G Loss: 0.000036, D Loss: 0.000016\n",
            "Epoch [1400/2000], G Loss: 0.000036, D Loss: 0.000002\n",
            "Epoch [1450/2000], G Loss: 0.000064, D Loss: 0.000005\n",
            "Epoch [1500/2000], G Loss: 0.000185, D Loss: 0.000428\n",
            "Epoch [1550/2000], G Loss: 0.000054, D Loss: 0.000132\n",
            "Epoch [1600/2000], G Loss: 0.000105, D Loss: 0.000009\n",
            "Epoch [1650/2000], G Loss: 0.000069, D Loss: 0.000116\n",
            "Epoch [1700/2000], G Loss: 0.000470, D Loss: -0.000234\n",
            "Epoch [1750/2000], G Loss: 0.000151, D Loss: -0.000247\n",
            "Epoch [1800/2000], G Loss: 0.000261, D Loss: 0.000050\n",
            "Epoch [1850/2000], G Loss: 0.000076, D Loss: -0.000003\n",
            "Epoch [1900/2000], G Loss: 0.000035, D Loss: 0.000012\n",
            "Epoch [1950/2000], G Loss: 0.000038, D Loss: -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-07 07:54:09,602] Trial 7 finished with value: 4.4146973345419624 and parameters: {'hidden_dim': 64, 'lstm_layers': 2, 'hidden_layer': 64, 'epochs': 2000, 'd_lr': 8.338713074153563e-05, 'g_lr': 0.0009226063792509045}. Best is trial 3 with value: 6.337192197484838.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2000/2000], G Loss: 0.000034, D Loss: 0.000008\n",
            "Epoch [50/1500], G Loss: 0.010722, D Loss: -0.010871\n",
            "Epoch [100/1500], G Loss: 0.008924, D Loss: -0.016516\n",
            "Epoch [150/1500], G Loss: 0.015158, D Loss: -0.004905\n",
            "Epoch [200/1500], G Loss: 0.010370, D Loss: -0.001247\n",
            "Epoch [250/1500], G Loss: 0.004217, D Loss: -0.001919\n",
            "Epoch [300/1500], G Loss: 0.007364, D Loss: -0.003616\n",
            "Epoch [350/1500], G Loss: 0.004053, D Loss: -0.000404\n",
            "Epoch [400/1500], G Loss: 0.001556, D Loss: 0.000703\n",
            "Epoch [450/1500], G Loss: 0.001414, D Loss: -0.000139\n",
            "Epoch [500/1500], G Loss: 0.001643, D Loss: 0.001132\n",
            "Epoch [550/1500], G Loss: 0.001707, D Loss: 0.000066\n",
            "Epoch [600/1500], G Loss: 0.001006, D Loss: 0.000259\n",
            "Epoch [650/1500], G Loss: 0.000652, D Loss: 0.000483\n",
            "Epoch [700/1500], G Loss: 0.000498, D Loss: 0.000063\n",
            "Epoch [750/1500], G Loss: 0.000515, D Loss: 0.000263\n",
            "Epoch [800/1500], G Loss: 0.000359, D Loss: 0.000209\n",
            "Epoch [850/1500], G Loss: 0.000496, D Loss: 0.000075\n",
            "Epoch [900/1500], G Loss: 0.000271, D Loss: 0.000163\n",
            "Epoch [950/1500], G Loss: 0.000295, D Loss: 0.000139\n",
            "Epoch [1000/1500], G Loss: 0.000262, D Loss: 0.000008\n",
            "Epoch [1050/1500], G Loss: 0.000316, D Loss: 0.000058\n",
            "Epoch [1100/1500], G Loss: 0.000294, D Loss: 0.000025\n",
            "Epoch [1150/1500], G Loss: 0.000124, D Loss: 0.000055\n",
            "Epoch [1200/1500], G Loss: 0.000147, D Loss: -0.000056\n",
            "Epoch [1250/1500], G Loss: 0.000184, D Loss: 0.000060\n",
            "Epoch [1300/1500], G Loss: 0.000490, D Loss: 0.000161\n",
            "Epoch [1350/1500], G Loss: 0.000246, D Loss: 0.000117\n",
            "Epoch [1400/1500], G Loss: 0.000321, D Loss: 0.000114\n",
            "Epoch [1450/1500], G Loss: 0.000105, D Loss: 0.000136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-07 07:56:42,102] Trial 8 finished with value: 4.33926484495242 and parameters: {'hidden_dim': 64, 'lstm_layers': 4, 'hidden_layer': 128, 'epochs': 1500, 'd_lr': 2.9196178233748825e-05, 'g_lr': 0.00029048010596313564}. Best is trial 3 with value: 6.337192197484838.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1500/1500], G Loss: 0.000144, D Loss: 0.000080\n",
            "Epoch [50/2000], G Loss: 0.004685, D Loss: -0.006986\n",
            "Epoch [100/2000], G Loss: 0.004346, D Loss: -0.026809\n",
            "Epoch [150/2000], G Loss: 0.018945, D Loss: -0.000381\n",
            "Epoch [200/2000], G Loss: 0.003968, D Loss: -0.003956\n",
            "Epoch [250/2000], G Loss: 0.007748, D Loss: -0.001555\n",
            "Epoch [300/2000], G Loss: 0.002899, D Loss: -0.008368\n",
            "Epoch [350/2000], G Loss: 0.006731, D Loss: -0.003182\n",
            "Epoch [400/2000], G Loss: 0.008784, D Loss: -0.001376\n",
            "Epoch [450/2000], G Loss: 0.003381, D Loss: -0.002053\n",
            "Epoch [500/2000], G Loss: 0.005065, D Loss: -0.001385\n",
            "Epoch [550/2000], G Loss: 0.015457, D Loss: -0.002860\n",
            "Epoch [600/2000], G Loss: 0.002214, D Loss: 0.000733\n",
            "Epoch [650/2000], G Loss: 0.002622, D Loss: 0.000314\n",
            "Epoch [700/2000], G Loss: 0.001568, D Loss: -0.000589\n",
            "Epoch [750/2000], G Loss: 0.003204, D Loss: -0.000061\n",
            "Epoch [800/2000], G Loss: 0.002242, D Loss: -0.003292\n",
            "Epoch [850/2000], G Loss: 0.001831, D Loss: -0.003974\n",
            "Epoch [900/2000], G Loss: 0.001449, D Loss: 0.000755\n",
            "Epoch [950/2000], G Loss: 0.001110, D Loss: 0.000745\n",
            "Epoch [1000/2000], G Loss: 0.000957, D Loss: 0.000563\n",
            "Epoch [1050/2000], G Loss: 0.001316, D Loss: 0.000221\n",
            "Epoch [1100/2000], G Loss: 0.001057, D Loss: -0.000144\n",
            "Epoch [1150/2000], G Loss: 0.001909, D Loss: 0.000183\n",
            "Epoch [1200/2000], G Loss: 0.000809, D Loss: 0.000204\n",
            "Epoch [1250/2000], G Loss: 0.000587, D Loss: 0.000107\n",
            "Epoch [1300/2000], G Loss: 0.000446, D Loss: 0.000199\n",
            "Epoch [1350/2000], G Loss: 0.000521, D Loss: -0.000270\n",
            "Epoch [1400/2000], G Loss: 0.000653, D Loss: -0.000045\n",
            "Epoch [1450/2000], G Loss: 0.000434, D Loss: 0.000125\n",
            "Epoch [1500/2000], G Loss: 0.000599, D Loss: 0.000093\n",
            "Epoch [1550/2000], G Loss: 0.000618, D Loss: -0.000073\n",
            "Epoch [1600/2000], G Loss: 0.000356, D Loss: 0.000050\n",
            "Epoch [1650/2000], G Loss: 0.000333, D Loss: 0.000080\n",
            "Epoch [1700/2000], G Loss: 0.000313, D Loss: -0.000026\n",
            "Epoch [1750/2000], G Loss: 0.000257, D Loss: 0.000124\n",
            "Epoch [1800/2000], G Loss: 0.000283, D Loss: 0.000077\n",
            "Epoch [1850/2000], G Loss: 0.000221, D Loss: 0.000042\n",
            "Epoch [1900/2000], G Loss: 0.000182, D Loss: 0.000045\n",
            "Epoch [1950/2000], G Loss: 0.000166, D Loss: 0.000054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-07 07:59:05,968] Trial 9 finished with value: 4.63107814774796 and parameters: {'hidden_dim': 64, 'lstm_layers': 2, 'hidden_layer': 32, 'epochs': 2000, 'd_lr': 4.073042329519963e-05, 'g_lr': 0.00010017757125833272}. Best is trial 3 with value: 6.337192197484838.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2000/2000], G Loss: 0.000226, D Loss: -0.000035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2550f61c"
      },
      "source": [
        "# Saving Best Hyperparameters\n",
        "\n",
        "This section saves the best hyperparameters found during the Optuna tuning process to a JSON file, allowing them to be easily reloaded later."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9etqCx1PXZ4",
        "outputId": "5ecfe63b-4bfc-48eb-c9c1-4cd5540ad55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hidden_dim': 128, 'lstm_layers': 4, 'hidden_layer': 128, 'epochs': 2000, 'd_lr': 0.0009255789089317319, 'g_lr': 0.00012586546042489945}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e174ae8",
        "outputId": "e890cc47-e2bc-4d3c-84ce-112c7358d75e"
      },
      "source": [
        "import json\n",
        "\n",
        "# Assuming best_params is already defined from the hyperparameter tuning\n",
        "# If not, make sure you run the cell above first.\n",
        "\n",
        "# Define the path where you want to save the file\n",
        "save_path = '/content/best_hyperparameters.json'\n",
        "\n",
        "# Save the dictionary to a JSON file\n",
        "with open(save_path, 'w') as f:\n",
        "    json.dump(best_params, f)\n",
        "\n",
        "print(f\"Best hyperparameters saved to {save_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters saved to /content/best_hyperparameters.json\n"
          ]
        }
      ]
    }
  ]
}